import streamlit as st
from google.generativeai import configure, GenerativeModel
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
load_dotenv()

# secrets.toml ë˜ëŠ” .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")

# API í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
if not api_key:
    st.error("â—ï¸API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml`ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# Gemini API êµ¬ì„±
configure(api_key=api_key)
model = GenerativeModel("gemini-1.5-flash")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ’˜ ì¸ íƒ€ëŠ” ê°ì • ë²ˆì—­ê¸°", layout="wide")

# ìŠ¤íƒ€ì¼ ì„¤ì •
st.markdown(
    """
    <style>
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton>button {
        background-color: #ffc0cb;
        color: #fff;
        border-radius: 12px;
        padding: 0.6em 1.2em;
        border: none;
        font-weight: bold;
        font-size: 1em;
        transition: 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #ff9aad;
        transform: scale(1.05);
    }

    /* í…ìŠ¤íŠ¸ ì—ì–´ë¦¬ì–´ */
    .stTextArea textarea {
        border-radius: 12px;
        border: 2px solid #ffc0cb;
        padding: 12px;
        background-color: #1e1e1e;
        color: #eee;
        font-size: 1em;
    }

    /* ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ */
    .stMarkdown {
        font-size: 1.1em;
        line-height: 1.6;
    }

    /* ì„¤ëª… ì¹´ë“œ */
    .card {
        padding: 12px;
        border-radius: 12px;
        margin-bottom: 8px;
    }

    .intro-card {
        background-color: #fce4ec;
        color: #333;
    }

    .role-card {
        background-color: #e3f2fd;
        color: #333;
    }

    /* ë§í’ì„  UI í‰ë‚´ */
    .user-bubble {
        background-color: #333;
        color: white;
        padding: 10px;
        border-radius: 12px;
        margin-bottom: 5px;
        text-align: left;
    }

    .bot-bubble {
        background-color: #ffc0cb;
        color: black;
        padding: 10px;
        border-radius: 12px;
        margin-bottom: 20px;
        text-align: left;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# í˜ì´ì§€ ì œëª©
st.title("ğŸ’˜ Crush Decoder ")

# ì„¤ëª… ë¬¸êµ¬
st.markdown("<div class='card intro-card'>ğŸ’¬ ìƒëŒ€ë°©ì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•´ ê°ì •ì„ í•´ì„í•˜ê³  ëŒ€ì‘ë²•ì„ ì•Œë ¤ì£¼ëŠ” ì—°ì•  ê°ì • ë¶„ì„ ì±—ë´‡ì…ë‹ˆë‹¤.</div>", unsafe_allow_html=True)


st.divider()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥ìš©)
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

# ê°ì • ë¶„ì„ í•¨ìˆ˜
def analyze_message(message: str) -> str:
    try:
        prompt = f"""
        ë„ˆëŠ” ì—°ì•  ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì•„ë˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•´ì„œ
        â‘  ê°ì • ì¶”ì •
        â‘¡ ìƒí™© í•´ì„
        â‘¢ ëŒ€ì‘ íŒ
        ì„ ê°ê° í•œ ë¬¸ë‹¨ì”© ì„¤ëª…í•´ì¤˜.

        ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ì— ì´ ìƒí™©ì— ì–´ìš¸ë¦¬ëŠ” ë‹µì¥ í•œ ë¬¸ì¥ì„ ì¶”ì²œí•´ì¤˜.
        ì˜ˆë¥¼ ë“¤ì–´ â€œê·¸ë¬êµ¬ë‚˜~ ìš”ì¦˜ ë§ì´ ë°”ë¹´ê² ë‹¤!â€ ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ë¬¸ì¥ì´ë©´ ì¢‹ì•„.

        "{message}"
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        if "API key" in str(e):
            return "â—ï¸API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        elif "network" in str(e).lower():
            return "âš ï¸ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        else:
            return "âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
def display_chat():
    for user_msg, bot_msg in st.session_state['chat_history']:
        # AI ë‹µì¥ ë¶„ë¦¬ (ê¸°ë³¸ íŒ¨í„´: "ì¶”ì²œ ë‹µì¥:" ë˜ëŠ” "ë‹µì¥:")
        reply_split = bot_msg.strip().split("ë‹µì¥:")
        main_analysis = reply_split[0].strip()
        ai_reply = reply_split[1].strip() if len(reply_split) > 1 else None

        # ì‚¬ìš©ì ë§í’ì„ 
        st.markdown(f"<div class='user-bubble'>ğŸ™‹â€â™€ï¸ <b>ë‚˜:</b> {user_msg}</div>", unsafe_allow_html=True)

        # ë¶„ì„ ê²°ê³¼ ë§í’ì„ 
        st.markdown(f"<div class='bot-bubble'>ğŸ¤– <b>ë¶„ì„:</b><br>{main_analysis}</div>", unsafe_allow_html=True)

        # AI ì¶”ì²œ ë‹µì¥ ê°•ì¡°
        if ai_reply:
            st.markdown(f"<div class='bot-bubble' style='background-color:#ffe4e1;'><b>ğŸ’Œ AI ì¶”ì²œ ë‹µì¥:</b> {ai_reply}</div>", unsafe_allow_html=True)

# ì…ë ¥ UI
st.write("### ğŸ’¬ ì¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
user_input = st.text_area("ì˜ˆ: 'ã…ã… ì•„ëƒ~ ê·¸ëƒ¥ ë³„ì¼ ì—†ì—ˆì–´ ã…‹ã…‹'", label_visibility="collapsed")

if st.button("ğŸ” ê°ì • ë¶„ì„í•˜ê¸°"):
    if user_input.strip():
        with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state['chat_history'].append((user_input, "ë¶„ì„ ì¤‘..."))
            response = analyze_message(user_input)
            st.session_state['chat_history'][-1] = (user_input, response)
    else:
        st.warning("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ëŒ€í™” ë‚´ìš© ì¶œë ¥
display_chat()

# -------------------------------------
# ğŸ’¾ ëŒ€í™” ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥
# -------------------------------------
if st.session_state['chat_history']:
    chat_export_text = ""
    for user_msg, bot_msg in st.session_state['chat_history']:
        chat_export_text += f"ğŸ™‹â€â™€ï¸ ë‚˜: {user_msg}\nğŸ¤– ë¶„ì„: {bot_msg}\n\n"

    st.download_button(
        label="ğŸ“„ ëŒ€í™” ë‚´ë³´ë‚´ê¸° (.txt)",
        data=chat_export_text,
        file_name="crush_decoder_chat.txt",
        mime="text/plain"
    )


# -------------------------------------
# ğŸ­ ì¸ ìƒëŒ€ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘
# -------------------------------------
st.divider()
st.subheader("ğŸ® ì¸ ìƒëŒ€ì™€ ê°€ìƒ ëŒ€í™”í•´ë³´ê¸°")

if st.button("ğŸ—¨ï¸ ì´ ì‚¬ëŒì´ë‘ ëŒ€í™”í•´ë³¼ë˜ìš”"):
    if not st.session_state['chat_history']:
        st.warning("ë¨¼ì € ìƒëŒ€ì˜ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê³  ë¶„ì„í•´ ì£¼ì„¸ìš”.")
    else:
        # ìµœê·¼ ë©”ì‹œì§€ë“¤ë¡œ ìºë¦­í„° ìŠ¤íƒ€ì¼ ì¶”ì¶œ
        messages = [msg for msg, _ in st.session_state['chat_history']]
        character_profile = "\n".join(f"- {m}" for m in messages[-5:])  # ìµœê·¼ 5ê°œ ê¸°ì¤€

        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì™€ ë¶„ì„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        last_user_msg, last_bot_msg = st.session_state['chat_history'][-1]
        reply_split = last_bot_msg.strip().split("ë‹µì¥:")
        analysis_text = reply_split[0].strip()
        ai_reply = reply_split[1].strip() if len(reply_split) > 1 else ""

        # ìºë¦­í„° ì„¤ì • í”„ë¡¬í”„íŠ¸
        st.session_state['sim_prompt'] = f"""
        ë„ˆëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë©”ì‹œì§€ë¥¼ ë³´ë‚¸ ì‚¬ëŒì²˜ëŸ¼ í–‰ë™í•´ì•¼ í•´:

        {character_profile}

        ì´ ì‚¬ëŒì€ ì¸ íƒ€ëŠ” ì¤‘ì´ë©°, ì§ì„¤ì ì´ê¸°ë³´ë‹¨ ì€ê·¼í•˜ê²Œ ê°ì •ì„ í‘œí˜„í•˜ëŠ” ìŠ¤íƒ€ì¼ì´ì•¼.
        ë©”ì‹œì§€ë¥¼ ë³´ë©´ ê°ì •ì„ ì§ì ‘ì ìœ¼ë¡œ ë§í•˜ì§„ ì•Šì§€ë§Œ, ì•½ê°„ì˜ ê±°ë¦¬ê°ê³¼ ë°€ë‹¹ì´ ëŠê»´ì ¸.
        ì§€ê¸ˆë¶€í„° ì‚¬ìš©ìê°€ ë„ˆì—ê²Œ ë§ì„ ê±¸ë©´, ì´ ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì‘í•´ì¤˜.

        ë‹¤ìŒì€ ë„¤ê°€ ì´ì „ì— ë³´ëƒˆë˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì•¼:
        "{last_user_msg}"

        ê·¸ë¦¬ê³  ì§€ê¸ˆ ë„ˆì˜ ê°ì • ìƒíƒœëŠ” ë‹¤ìŒê³¼ ê°™ì•„:
        {analysis_text.replace('\n', ' ')} 

        ê·¸ ìƒí™©ì„ ê¸°ì–µí•˜ë©´ì„œ ëŒ€ë‹µí•´ì¤˜.
        ë§íˆ¬ëŠ” ìì—°ìŠ¤ëŸ½ê³  ê°ì •ì´ ë‹´ê¸´ ë§íˆ¬ì—¬ì•¼ í•´.
        """

        # ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state['sim_mode'] = True
        st.session_state['sim_history'] = []

        # ì²« ëŒ€ì‚¬: ìƒëŒ€ê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ í•œ ë§ì„ ë‹¤ì‹œ ì–¸ê¸‰
        st.session_state['sim_history'].append((
            "assistant",
            last_user_msg
        ))

# -------------------------------------
# ğŸ’¬ ì‹œë®¬ë ˆì´ì…˜ ì±— ì¸í„°í˜ì´ìŠ¤
# -------------------------------------
if st.session_state.get('sim_mode'):
    st.divider()
    st.subheader("ğŸ’ ê°€ìƒ ì¸ ìƒëŒ€ì™€ ëŒ€í™” ì¤‘...")

    if 'sim_history' not in st.session_state:
        st.session_state['sim_history'] = []

    for role, msg in st.session_state['sim_history']:
        with st.chat_message(role):
            st.write(msg)

    user_msg = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš” ğŸ’Œ")
    if user_msg:
        with st.chat_message("user"):
            st.write(user_msg)
        with st.spinner("ìƒê° ì¤‘..."):
            sim_prompt = st.session_state['sim_prompt'] + f'\n\nì‚¬ìš©ì: "{user_msg}"\nìƒëŒ€ë°©:'
            reply = model.generate_content(sim_prompt).text
        st.session_state['sim_history'].append(("user", user_msg))
        st.session_state['sim_history'].append(("assistant", reply))
        with st.chat_message("assistant"):
            st.write(reply)
